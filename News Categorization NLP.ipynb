{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb07fda",
   "metadata": {},
   "source": [
    "## NLP News Topic Analysis & Classification\n",
    "\n",
    "The goal of this project is to create a model that maximes accuracy in classifying new articles based on their headlines.  The dataset, cited below, provides in `.json` format article information with categorization regarding the associated predominant topic.  This includes a link to the article, the headline, the data published, and a short description.  I'll use the NLTK library in order to tokenize the text information, determine the lemmas for each word and part of speech, and engineer features based on this information.  I'll apply several different kinds of machine learning classifiers to see how high an accuracy score we can generate on a 'test' portion of the data, training/validating on the remaining portion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7027ef",
   "metadata": {},
   "source": [
    "**Kaggle page: https://www.kaggle.com/datasets/rmisra/news-category-dataset**\n",
    "\n",
    "**Dataset source: https://rishabhmisra.github.io/publications**\n",
    "\n",
    "1. Misra, Rishabh. \"News Category Dataset.\" arXiv preprint arXiv:2209.11429 (2022).\n",
    "2. Misra, Rishabh and Jigyasa Grover. \"Sculpting Data for ML: The first act of Machine Learning.\" ISBN 9798585463570 (2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd5b372",
   "metadata": {},
   "source": [
    "Let's import the initial NLTK libraries we'll be using for tokenization, lemmatization, and identification for part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a0fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dmark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dmark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dmark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "file_path = 'News_Category_Dataset_v3.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8155e",
   "metadata": {},
   "source": [
    "We'll read the json into a dataframe and check to see how large it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a876bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209527, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(file_path, lines=True)\n",
    "rows_num = int(data.shape[0])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21aa77a",
   "metadata": {},
   "source": [
    "Fairly large-- more than 200,000 instances.  Let's get a look at those 6 columns and their datatypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aeb8d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['link', 'headline', 'category', 'short_description', 'authors', 'date']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "link                         object\n",
       "headline                     object\n",
       "category                     object\n",
       "short_description            object\n",
       "authors                      object\n",
       "date                 datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(data.columns))\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7cdfc",
   "metadata": {},
   "source": [
    "Now we can take a look at what kind of entries fall under each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4645a995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-23  \n",
       "3 2022-09-23  \n",
       "4 2022-09-22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766cca1c",
   "metadata": {},
   "source": [
    "Let's check if any records have null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71019172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e179b55",
   "metadata": {},
   "source": [
    "Nope-- we'll be able to keep all these records.  Now we can get a closer look at the topics that fall under the `category` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4914d5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS          35602\n",
       "WELLNESS          17945\n",
       "ENTERTAINMENT     17362\n",
       "TRAVEL             9900\n",
       "STYLE & BEAUTY     9814\n",
       "PARENTING          8791\n",
       "HEALTHY LIVING     6694\n",
       "QUEER VOICES       6347\n",
       "FOOD & DRINK       6340\n",
       "BUSINESS           5992\n",
       "COMEDY             5400\n",
       "SPORTS             5077\n",
       "BLACK VOICES       4583\n",
       "HOME & LIVING      4320\n",
       "PARENTS            3955\n",
       "THE WORLDPOST      3664\n",
       "WEDDINGS           3653\n",
       "WOMEN              3572\n",
       "CRIME              3562\n",
       "IMPACT             3484\n",
       "DIVORCE            3426\n",
       "WORLD NEWS         3299\n",
       "MEDIA              2944\n",
       "WEIRD NEWS         2777\n",
       "GREEN              2622\n",
       "WORLDPOST          2579\n",
       "RELIGION           2577\n",
       "STYLE              2254\n",
       "SCIENCE            2206\n",
       "TECH               2104\n",
       "TASTE              2096\n",
       "MONEY              1756\n",
       "ARTS               1509\n",
       "ENVIRONMENT        1444\n",
       "FIFTY              1401\n",
       "GOOD NEWS          1398\n",
       "U.S. NEWS          1377\n",
       "ARTS & CULTURE     1339\n",
       "COLLEGE            1144\n",
       "LATINO VOICES      1130\n",
       "CULTURE & ARTS     1074\n",
       "EDUCATION          1014\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6f7af",
   "metadata": {},
   "source": [
    "May of these are ambiguous.  Some also seem to overlap.  Let's make our life a little bit easier and get rid of the instances/rows with category lables that seem not to be distinct catgories.  These might overlap but might not, so we'll simply jettison them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a5b4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178124, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categories whose instances we'll remove\n",
    "DROP_CATS = ['COLLEGE','GOOD NEWS','FIFTY','WEIRD NEWS','TASTE','WOMEN','IMPACT','GREEN','WEDDINGS','MONEY',\n",
    "            'LATINO VOICES','MEDIA','DIVORCE','MONEY']\n",
    "# Create a list of the indexes that we've marked True, if their category label is in our drop list\n",
    "DROP_IDX = data[data['category'].map(lambda x:True if x in DROP_CATS else False)].index\n",
    "data.drop(index=DROP_IDX, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a7071",
   "metadata": {},
   "source": [
    "Looking at the shape, we got rid of a decent number of instances, but we still have the vast majority.  Now let's unite some categories that seem to cover the same topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750cf6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS          35602\n",
       "WELLNESS          17945\n",
       "ENTERTAINMENT     17362\n",
       "PARENTING         12746\n",
       "STYLE & BEAUTY    12068\n",
       "TRAVEL             9900\n",
       "WORLD NEWS         9542\n",
       "HEALTHY LIVING     6694\n",
       "QUEER VOICES       6347\n",
       "FOOD & DRINK       6340\n",
       "BUSINESS           5992\n",
       "COMEDY             5400\n",
       "SPORTS             5077\n",
       "BLACK VOICES       4583\n",
       "HOME & LIVING      4320\n",
       "SCIENCE & TECH     4310\n",
       "ARTS & CULTURE     3922\n",
       "CRIME              3562\n",
       "RELIGION           2577\n",
       "ENVIRONMENT        1444\n",
       "U.S. NEWS          1377\n",
       "EDUCATION          1014\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMBINE_CATS = {'SCIENCE':'SCIENCE & TECH','TECH':'SCIENCE & TECH',\n",
    "               'STYLE':'STYLE & BEAUTY','PARENTS':'PARENTING',\n",
    "               'THE WORLDPOST':'WORLD NEWS','WORLDPOST':'WORLD NEWS',\n",
    "               'ARTS':'ARTS & CULTURE','CULTURE & ARTS':'ARTS & CULTURE'}\n",
    "# If the topic is in the dictionary, we can convert it; otherwise, keep the topic as is\n",
    "data['category'] = data['category'].map(lambda x:COMBINE_CATS[x] if x in COMBINE_CATS.keys() else x)\n",
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7ad5c",
   "metadata": {},
   "source": [
    "Now we can start to build out a feature set based on the text of the headlines and/or the descriptions.  I'm not going to look at the descriptions for now, for two reasons.  One is it is going to pull a substantial amount of processing power just parsing and working with the headline text.  Second is that I am curious as to how well we can build a classifier on more limited information (i.e., only the headline).  We'll drop columns we don't care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38add253",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['link','authors','date','short_description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba16bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline   category\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS\n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS\n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY\n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING\n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0231cdf8",
   "metadata": {},
   "source": [
    "Now we can do some work.  I'm going to first create tokens using NLTK's word_tokenize method, and then take those values and convert them to NLTK Text class.  I'll also add up the number of words and add this as a feature column.  If we look at the data, we can see the new columns and their formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ce1b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>headline_text</th>\n",
       "      <th>headline_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>(Over, 4, Million, Americans, Roll, Up, Sleeve...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>(American, Airlines, Flyer, Charged, ,, Banned...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>(23, Of, The, Funniest, Tweets, About, Cats, A...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>(The, Funniest, Tweets, From, Parents, This, W...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>(Woman, Who, Called, Cops, On, Black, Bird-Wat...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                       headline_text  headline_len  \n",
       "0  (Over, 4, Million, Americans, Roll, Up, Sleeve...            11  \n",
       "1  (American, Airlines, Flyer, Charged, ,, Banned...            14  \n",
       "2  (23, Of, The, Funniest, Tweets, About, Cats, A...            15  \n",
       "3  (The, Funniest, Tweets, From, Parents, This, W...            11  \n",
       "4  (Woman, Who, Called, Cops, On, Black, Bird-Wat...            11  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headline_text'] = data['headline'].map(nltk.word_tokenize).map(nltk.Text)\n",
    "data['headline_len'] = data['headline_text'].map(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e013c1",
   "metadata": {},
   "source": [
    "## Lemmatization & POS Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d427220",
   "metadata": {},
   "source": [
    "I want to assign a part of speech to each word too, since some words in english can be a noun or a verb and be more or less useful to a classifier.  I at least want to caputre that differnece so it can be seen by the models.  First we'll identify our list of parts of speech (`poss`) that NLTK's lemmatizer can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb8cbac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the key parts of speech we can lemmatize off of.  I'll drop 's' as in my testing of this \n",
    "# program, I noticed that no instances of 's' show up, and we'll want to save some time when we loop through this\n",
    "# massive dataset\n",
    "poss = ['v','n','a','r']#,'s']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9ffb0",
   "metadata": {},
   "source": [
    "Next we'll define a function that will take the part of speech tag that NLTK's pos_tag will provide and convert it back to the tag that NLTK's lemmatizer works with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1545b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(tag):    \n",
    "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
    "    try:\n",
    "        return tag_dict[tag[0]]\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4edb0",
   "metadata": {},
   "source": [
    "Lemmatization will take each word down to its root, depending on the part of speech we are applying. So, our plan is to go through each part of speech and each row of the data.  We'll take the headline text and then lemmatize the word.  We'll take that word, identify the part of speech, and then create a string of the lemmatized word concatenated with its part of speech.  We'll store these values in columns related to the lemma pos we applied.  The results will be strings in each column that have the lemmatized word coded by its pos.  These will eventually be our features for our models to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67f98f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING \n",
    "# def lemm(pos,row,l):\n",
    "#     # create a list of lemmatized words based on the pos, and making sure it is an actual word and not an empty string\n",
    "#     lemmas = [lemmatizer.lemmatize(word.lower(),pos) for word in l if (word and word[0].isalpha())]\n",
    "#     # Create a list of pos tags from the lemmatized words\n",
    "#     pos_tags = nltk.pos_tag(lemmas, lang='eng')\n",
    "#     # Save a string of the words + the nltk-identified pos\n",
    "#     return ' '.join([word+pos for word, pos_tag in pos_tags if convert_tag(pos_tag) == pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "020dcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING \n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# for pos in poss:\n",
    "#     data[f'headline_lemmas_{pos}'] = [list() for x in range(len(data.index))]\n",
    "\n",
    "# print('Headline Lemmatization & Word POS Classification')\n",
    "# input = [(pos,row,data.loc[row,'headline_text']) for pos in poss for row in data.index]\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     with Pool(8) as p:\n",
    "#         results = p.map(lemm, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20cf2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've run this before and it takes a while, so I've saved previous results in a csv file and will load it \n",
    "# if it exists\n",
    "try:\n",
    "    data = pd.read_csv('data.csv')\n",
    "except:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    print('Headline Lemmatization & Word POS Classification')\n",
    "    # Pick part of speech for lemmatization\n",
    "    for pos in poss:\n",
    "        print(f'Working on {pos}')\n",
    "        # Create an empty column related to the lemmatization pos\n",
    "        data[f'headline_lemmas_{pos}'] = [list() for x in range(len(data.index))]\n",
    "        # Parse each row\n",
    "        for row in data.index:\n",
    "            if row % int(rows_num/4) == 0:\n",
    "                print(f'{row//int(rows_num/4)*25}% complete')\n",
    "            # create a list of lemmatized words based on the pos, and making sure it is an actual word and not an empty string\n",
    "            lemmas = [lemmatizer.lemmatize(word.lower(),pos) for word in data.at[row,'headline_text'] if (word and word[0].isalpha())]\n",
    "            # Create a list of pos tags from the lemmatized words\n",
    "            pos_tags = nltk.pos_tag(lemmas, lang='eng')\n",
    "            # Save a string of the words + the nltk-identified pos\n",
    "            data.at[row,f'headline_lemmas_{pos}'] = ' '.join([word+pos for word, pos_tag in pos_tags if convert_tag(pos_tag) == pos])\n",
    "# The .csv file-save-to-pd-reload changes blank strings to NaN, so changing those back\n",
    "data.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160e8eec",
   "metadata": {},
   "source": [
    "We can move on to our models. . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be8665",
   "metadata": {},
   "source": [
    "## Feature Engineering & Train/Test Split\n",
    "\n",
    "We'll import the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8087d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b503989",
   "metadata": {},
   "source": [
    "I'll work from a copy of the data so far, in case we need to come back to it.  `data2` will what we build our feature set and targets off of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca1cad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86017fd8",
   "metadata": {},
   "source": [
    "Our original texts have served their purpose, so we'll drop them off to make working with data2 a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6872f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data2.drop(columns=['headline','headline_text'],inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a642be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>headline_len</th>\n",
       "      <th>headline_lemmas_v</th>\n",
       "      <th>headline_lemmas_n</th>\n",
       "      <th>headline_lemmas_a</th>\n",
       "      <th>headline_lemmas_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>11</td>\n",
       "      <td>rollv</td>\n",
       "      <td>rolln sleeven covidn boostern</td>\n",
       "      <td>omicron-targeteda</td>\n",
       "      <td>upr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>14</td>\n",
       "      <td>chargev</td>\n",
       "      <td>airlinen flyern lifen flightn attendantn videon</td>\n",
       "      <td>americana</td>\n",
       "      <td>flyerr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>tweetn catn dogn weekn sept.n</td>\n",
       "      <td>funnya</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   category  headline_len headline_lemmas_v  \\\n",
       "0           0  U.S. NEWS            11             rollv   \n",
       "1           1  U.S. NEWS            14           chargev   \n",
       "2           2     COMEDY            15                     \n",
       "\n",
       "                                 headline_lemmas_n  headline_lemmas_a  \\\n",
       "0                    rolln sleeven covidn boostern  omicron-targeteda   \n",
       "1  airlinen flyern lifen flightn attendantn videon          americana   \n",
       "2                    tweetn catn dogn weekn sept.n             funnya   \n",
       "\n",
       "  headline_lemmas_r  \n",
       "0               upr  \n",
       "1            flyerr  \n",
       "2                    "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938ccf1",
   "metadata": {},
   "source": [
    "I want to combine all of the lemmatized, pos-coded words into one string to allow our vectorizer to work on it.  I'll work with just the columns that have those terms, and then I'll concatenate all of these words into a new column called 'headline_lemmas.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e740976",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_lemma_col_idx = [i for i,col in enumerate(data2.columns) if col.find('headline_lemmas') != -1]\n",
    "headline_lemma_cols = [col for i,col in enumerate(data2.columns) if col.find('headline_lemmas') != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32b0f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['headline_lemmas'] = ''\n",
    "for col_idx in headline_lemma_col_idx:\n",
    "    data2['headline_lemmas'] += data2.iloc[:,col_idx] + ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5272c",
   "metadata": {},
   "source": [
    "Now we'll drop the columns that had the lemmas-pos words, as we don't need them any more.  We'll take a look at our data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "284aa97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(columns=headline_lemma_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0d7b1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>headline_len</th>\n",
       "      <th>headline_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>11</td>\n",
       "      <td>rollv rolln sleeven covidn boostern omicron-ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>14</td>\n",
       "      <td>chargev airlinen flyern lifen flightn attendan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>15</td>\n",
       "      <td>tweetn catn dogn weekn sept.n funnya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>11</td>\n",
       "      <td>tweetn parentn weekn sept.n funnya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>11</td>\n",
       "      <td>callv womann copn losesn lawsuitn ex-employern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   category  headline_len  \\\n",
       "0           0  U.S. NEWS            11   \n",
       "1           1  U.S. NEWS            14   \n",
       "2           2     COMEDY            15   \n",
       "3           3  PARENTING            11   \n",
       "4           4  U.S. NEWS            11   \n",
       "\n",
       "                                     headline_lemmas  \n",
       "0  rollv rolln sleeven covidn boostern omicron-ta...  \n",
       "1  chargev airlinen flyern lifen flightn attendan...  \n",
       "2             tweetn catn dogn weekn sept.n funnya    \n",
       "3               tweetn parentn weekn sept.n funnya    \n",
       "4  callv womann copn losesn lawsuitn ex-employern...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d689238",
   "metadata": {},
   "source": [
    "Let's construct the feature set and target, essentially just separating the category label column from the rest of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd6e845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2.copy()\n",
    "y = X.pop('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c87763",
   "metadata": {},
   "source": [
    "We'll create a split of our data and use the Tfidf Vectorizer to take each term in our lemmas-pos combo and create a sparse matrix relating to the occurence of each term in a give headline/instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1a3cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=126)\n",
    "X_train1 = X_train.pop('headline_lemmas')\n",
    "# Instatiate vectorizer and fit it on the lemma-pos terms\n",
    "vect_Tfidf = TfidfVectorizer().fit(X_train1)\n",
    "features = list(vect_Tfidf.get_feature_names_out())\n",
    "X_train1_v = vect_Tfidf.transform(X_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc13ee",
   "metadata": {},
   "source": [
    "I want to add the length of the headline back in, so we'll create a fucntion that will let us do that while keeping the sparse nature of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43a6b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a69feb",
   "metadata": {},
   "source": [
    "Now we can add that length of the headline back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20627139",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v = add_feature(X_train1_v, X_train['headline_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d7411f",
   "metadata": {},
   "source": [
    "We'll take the same steps as above, now for our testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f849c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test.pop('headline_lemmas')\n",
    "X_test1_v = vect_Tfidf.transform(X_test1)\n",
    "X_test_v = add_feature(X_test1_v, X_test['headline_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ea743",
   "metadata": {},
   "source": [
    "Tf-Idf isn't the only vecotrizer we can.  We can also try out the CountVectorizer.  This vectorizer allows us to consider n-grams as well.  This will help to see if word combo sequences are helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d71696db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect_ct = CountVectorizer(min_df=2, ngram_range=(2,5), analyzer='char_wb').fit(X_train1)\n",
    "features = list(vect_ct.get_feature_names_out())\n",
    "X_train1_vc = vect_ct.transform(X_train1)\n",
    "X_train_vc = add_feature(X_train1_vc, X_train['headline_len'])\n",
    "X_test1_vc = vect_ct.transform(X_test1)\n",
    "X_test_vc = add_feature(X_test1_vc, X_test['headline_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8036d8",
   "metadata": {},
   "source": [
    "## Grid Search & Model Parameter Tuning\n",
    "\n",
    "Time to build some classifiers.  We'll try 4 different classifiers, and we'll keep track of how they do to see which is best (based on accuracy on the testing split).  I'll use GridSearch to try to tune the parameters to get the best fit that we can on the training data, but we'll avoid overfitting by judging the \"best\" one on the testing split, as noted.  I'll print a classification report for each as well, but mostly for reference.  Again, accuracy is what I'm looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19945380",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_score = 0\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe53d63",
   "metadata": {},
   "source": [
    "#### Classifer 1 -- Multinomial Naive Bayes\n",
    "\n",
    "We'll run this twice, once with the training/test sets vectorized with Tf-Idf, and the other with the sets vectorized with Count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6f2053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = 3\n",
    "mnb_params = {'alpha':[0.01, 0.1, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56788a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best (Training) Params: {'alpha': 0.01}\n",
      "Best (Training) Estimator: MultinomialNB(alpha=0.01)\n",
      "Best (Training) Score: 0.8281843992108175\n",
      "Validation Score: 0.5926868520528463 \n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.52      0.30      0.38      1187\n",
      "  BLACK VOICES       0.45      0.24      0.31      1350\n",
      "      BUSINESS       0.55      0.34      0.42      1802\n",
      "        COMEDY       0.47      0.27      0.34      1564\n",
      "         CRIME       0.56      0.45      0.50      1074\n",
      "     EDUCATION       0.39      0.08      0.13       300\n",
      " ENTERTAINMENT       0.56      0.69      0.62      5190\n",
      "   ENVIRONMENT       0.55      0.20      0.30       485\n",
      "  FOOD & DRINK       0.74      0.66      0.70      1886\n",
      "HEALTHY LIVING       0.30      0.13      0.18      1991\n",
      " HOME & LIVING       0.71      0.52      0.60      1323\n",
      "     PARENTING       0.54      0.57      0.56      3837\n",
      "      POLITICS       0.61      0.85      0.71     10606\n",
      "  QUEER VOICES       0.65      0.46      0.54      1885\n",
      "      RELIGION       0.63      0.30      0.40       728\n",
      "SCIENCE & TECH       0.56      0.37      0.45      1297\n",
      "        SPORTS       0.73      0.57      0.64      1543\n",
      "STYLE & BEAUTY       0.71      0.73      0.72      3670\n",
      "        TRAVEL       0.65      0.64      0.65      2980\n",
      "     U.S. NEWS       0.29      0.08      0.13       406\n",
      "      WELLNESS       0.52      0.65      0.58      5403\n",
      "    WORLD NEWS       0.66      0.60      0.63      2931\n",
      "\n",
      "      accuracy                           0.59     53438\n",
      "     macro avg       0.56      0.44      0.48     53438\n",
      "  weighted avg       0.58      0.59      0.57     53438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tf-Idf-Vectorized sets\n",
    "grid = GridSearchCV(mnb, param_grid=mnb_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_v, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_v, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_v,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_v,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_v)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4545152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best (Training) Params: {'alpha': 1.0}\n",
      "Best (Training) Estimator: MultinomialNB()\n",
      "Best (Training) Score: 0.6676611648460934\n",
      "Validation Score: 0.609622366106516 \n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.49      0.37      0.42      1187\n",
      "  BLACK VOICES       0.41      0.38      0.39      1350\n",
      "      BUSINESS       0.46      0.49      0.48      1802\n",
      "        COMEDY       0.44      0.41      0.42      1564\n",
      "         CRIME       0.46      0.60      0.52      1074\n",
      "     EDUCATION       0.59      0.12      0.20       300\n",
      " ENTERTAINMENT       0.60      0.64      0.62      5190\n",
      "   ENVIRONMENT       0.62      0.19      0.29       485\n",
      "  FOOD & DRINK       0.68      0.68      0.68      1886\n",
      "HEALTHY LIVING       0.29      0.20      0.24      1991\n",
      " HOME & LIVING       0.63      0.66      0.65      1323\n",
      "     PARENTING       0.55      0.66      0.60      3837\n",
      "      POLITICS       0.78      0.72      0.75     10606\n",
      "  QUEER VOICES       0.61      0.61      0.61      1885\n",
      "      RELIGION       0.55      0.41      0.47       728\n",
      "SCIENCE & TECH       0.47      0.46      0.46      1297\n",
      "        SPORTS       0.62      0.64      0.63      1543\n",
      "STYLE & BEAUTY       0.73      0.74      0.74      3670\n",
      "        TRAVEL       0.66      0.70      0.68      2980\n",
      "     U.S. NEWS       0.34      0.08      0.13       406\n",
      "      WELLNESS       0.55      0.60      0.57      5403\n",
      "    WORLD NEWS       0.61      0.72      0.66      2931\n",
      "\n",
      "      accuracy                           0.61     53438\n",
      "     macro avg       0.55      0.50      0.51     53438\n",
      "  weighted avg       0.61      0.61      0.60     53438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counter-Vectorized sets\n",
    "mnbc = MultinomialNB()\n",
    "grid = GridSearchCV(mnbc, param_grid=mnb_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_vc, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_vc, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_vc,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_vc,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_vc)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a6957",
   "metadata": {},
   "source": [
    "#### Classifer 2 -- Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46bb171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "cv = 3\n",
    "tree_params = {'max_depth':[6,12,18]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e035bca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best (Training) Params: {'max_depth': 18}\n",
      "Best (Training) Estimator: DecisionTreeClassifier(max_depth=18)\n",
      "Best (Training) Score: 0.30942527629405064\n",
      "Validation Score: 0.30075975897301543 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.98      0.03      0.07      1187\n",
      "  BLACK VOICES       0.52      0.16      0.24      1350\n",
      "      BUSINESS       0.28      0.00      0.01      1802\n",
      "        COMEDY       0.68      0.08      0.14      1564\n",
      "         CRIME       0.46      0.01      0.01      1074\n",
      "     EDUCATION       0.00      0.00      0.00       300\n",
      " ENTERTAINMENT       0.46      0.01      0.01      5190\n",
      "   ENVIRONMENT       0.96      0.10      0.18       485\n",
      "  FOOD & DRINK       0.90      0.17      0.29      1886\n",
      "HEALTHY LIVING       0.00      0.00      0.00      1991\n",
      " HOME & LIVING       0.89      0.18      0.30      1323\n",
      "     PARENTING       0.67      0.29      0.40      3837\n",
      "      POLITICS       0.26      0.83      0.40     10606\n",
      "  QUEER VOICES       0.80      0.17      0.28      1885\n",
      "      RELIGION       0.87      0.05      0.09       728\n",
      "SCIENCE & TECH       0.25      0.00      0.00      1297\n",
      "        SPORTS       0.00      0.00      0.00      1543\n",
      "STYLE & BEAUTY       0.61      0.42      0.50      3670\n",
      "        TRAVEL       0.62      0.16      0.25      2980\n",
      "     U.S. NEWS       0.00      0.00      0.00       406\n",
      "      WELLNESS       0.21      0.51      0.30      5403\n",
      "    WORLD NEWS       0.46      0.00      0.00      2931\n",
      "\n",
      "      accuracy                           0.30     53438\n",
      "     macro avg       0.50      0.14      0.16     53438\n",
      "  weighted avg       0.45      0.30      0.23     53438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(tree, param_grid=tree_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_v, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_v, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_v,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_v,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_v)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f606f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best (Training) Params: {'max_depth': 18}\n",
      "Best (Training) Estimator: DecisionTreeClassifier(max_depth=18)\n",
      "Best (Training) Score: 0.3288901721123462\n",
      "Validation Score: 0.3146824357198997 \n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.38      0.01      0.01      1187\n",
      "  BLACK VOICES       0.53      0.02      0.04      1350\n",
      "      BUSINESS       0.38      0.00      0.01      1802\n",
      "        COMEDY       0.65      0.09      0.17      1564\n",
      "         CRIME       0.40      0.00      0.01      1074\n",
      "     EDUCATION       0.00      0.00      0.00       300\n",
      " ENTERTAINMENT       0.30      0.01      0.01      5190\n",
      "   ENVIRONMENT       0.84      0.10      0.17       485\n",
      "  FOOD & DRINK       0.88      0.18      0.30      1886\n",
      "HEALTHY LIVING       0.45      0.01      0.01      1991\n",
      " HOME & LIVING       0.89      0.17      0.28      1323\n",
      "     PARENTING       0.68      0.32      0.43      3837\n",
      "      POLITICS       0.31      0.76      0.44     10606\n",
      "  QUEER VOICES       0.78      0.29      0.42      1885\n",
      "      RELIGION       0.00      0.00      0.00       728\n",
      "SCIENCE & TECH       0.26      0.00      0.01      1297\n",
      "        SPORTS       0.38      0.00      0.01      1543\n",
      "STYLE & BEAUTY       0.57      0.43      0.49      3670\n",
      "        TRAVEL       0.74      0.19      0.31      2980\n",
      "     U.S. NEWS       0.00      0.00      0.00       406\n",
      "      WELLNESS       0.20      0.73      0.31      5403\n",
      "    WORLD NEWS       0.35      0.00      0.01      2931\n",
      "\n",
      "      accuracy                           0.31     53438\n",
      "     macro avg       0.45      0.15      0.16     53438\n",
      "  weighted avg       0.44      0.31      0.24     53438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "treec = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(treec, param_grid=tree_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_vc, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_vc, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_vc,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_vc,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_vc)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979f205",
   "metadata": {},
   "source": [
    "#### Classifer 3 -- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aad0fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "cv = 2\n",
    "mf = int(np.sqrt(len(features)))\n",
    "rf_params = {\n",
    "    'n_estimators':[100,200],\n",
    "    'max_depth':[15,25],\n",
    "    'max_features':[mf]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62a9ae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Best (Training) Params: {'max_depth': 25, 'max_features': 344, 'n_estimators': 200}\n",
      "Best (Training) Estimator: RandomForestClassifier(max_depth=25, max_features=344, n_estimators=200)\n",
      "Best (Training) Score: 0.2778820396836854\n",
      "Validation Score: 0.2704442531531869 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.00      0.00      0.00      1187\n",
      "  BLACK VOICES       0.00      0.00      0.00      1350\n",
      "      BUSINESS       0.00      0.00      0.00      1802\n",
      "        COMEDY       0.00      0.00      0.00      1564\n",
      "         CRIME       0.00      0.00      0.00      1074\n",
      "     EDUCATION       0.00      0.00      0.00       300\n",
      " ENTERTAINMENT       0.81      0.06      0.12      5190\n",
      "   ENVIRONMENT       0.00      0.00      0.00       485\n",
      "  FOOD & DRINK       0.92      0.16      0.27      1886\n",
      "HEALTHY LIVING       0.00      0.00      0.00      1991\n",
      " HOME & LIVING       1.00      0.04      0.08      1323\n",
      "     PARENTING       0.76      0.24      0.37      3837\n",
      "      POLITICS       0.22      1.00      0.36     10606\n",
      "  QUEER VOICES       0.89      0.05      0.09      1885\n",
      "      RELIGION       0.00      0.00      0.00       728\n",
      "SCIENCE & TECH       0.00      0.00      0.00      1297\n",
      "        SPORTS       0.00      0.00      0.00      1543\n",
      "STYLE & BEAUTY       0.86      0.38      0.53      3670\n",
      "        TRAVEL       0.98      0.04      0.07      2980\n",
      "     U.S. NEWS       0.00      0.00      0.00       406\n",
      "      WELLNESS       0.68      0.13      0.21      5403\n",
      "    WORLD NEWS       0.00      0.00      0.00      2931\n",
      "\n",
      "      accuracy                           0.27     53438\n",
      "     macro avg       0.32      0.09      0.09     53438\n",
      "  weighted avg       0.45      0.27      0.18     53438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(rf, param_grid=rf_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_v, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_v, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_v,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_v,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_v)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a3ef784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Best (Training) Params: {'max_depth': 25, 'max_features': 344, 'n_estimators': 100}\n",
      "Best (Training) Estimator: RandomForestClassifier(max_depth=25, max_features=344)\n",
      "Best (Training) Score: 0.4236401841425661\n",
      "Validation Score: 0.39019050114150977 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       1.00      0.01      0.01      1187\n",
      "  BLACK VOICES       0.54      0.14      0.22      1350\n",
      "      BUSINESS       0.90      0.03      0.05      1802\n",
      "        COMEDY       0.79      0.09      0.16      1564\n",
      "         CRIME       0.00      0.00      0.00      1074\n",
      "     EDUCATION       0.00      0.00      0.00       300\n",
      " ENTERTAINMENT       0.68      0.23      0.34      5190\n",
      "   ENVIRONMENT       1.00      0.10      0.18       485\n",
      "  FOOD & DRINK       0.90      0.23      0.37      1886\n",
      "HEALTHY LIVING       0.00      0.00      0.00      1991\n",
      " HOME & LIVING       0.89      0.23      0.36      1323\n",
      "     PARENTING       0.66      0.47      0.55      3837\n",
      "      POLITICS       0.28      0.96      0.43     10606\n",
      "  QUEER VOICES       0.84      0.41      0.55      1885\n",
      "      RELIGION       1.00      0.06      0.11       728\n",
      "SCIENCE & TECH       1.00      0.02      0.04      1297\n",
      "        SPORTS       0.74      0.02      0.03      1543\n",
      "STYLE & BEAUTY       0.58      0.58      0.58      3670\n",
      "        TRAVEL       0.84      0.23      0.36      2980\n",
      "     U.S. NEWS       0.00      0.00      0.00       406\n",
      "      WELLNESS       0.47      0.48      0.47      5403\n",
      "    WORLD NEWS       0.86      0.08      0.15      2931\n",
      "\n",
      "      accuracy                           0.39     53438\n",
      "     macro avg       0.64      0.20      0.23     53438\n",
      "  weighted avg       0.59      0.39      0.33     53438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "grid = GridSearchCV(rfc, param_grid=rf_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_vc, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_vc, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_vc,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_vc,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_vc)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140f99c",
   "metadata": {},
   "source": [
    "#### Classifer 4 -- AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e24578ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "cv = 2\n",
    "ada_params = {\n",
    "#     'n_estimators':[50,150],\n",
    "#     'learning_rate':[0.1,0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6c1324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Best (Training) Params: {}\n",
      "Best (Training) Estimator: AdaBoostClassifier()\n",
      "Best (Training) Score: 0.32892225269877934\n",
      "Validation Score: 0.3297279089786294 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.54      0.16      0.25      1187\n",
      "  BLACK VOICES       0.47      0.17      0.25      1350\n",
      "      BUSINESS       0.56      0.06      0.11      1802\n",
      "        COMEDY       0.23      0.19      0.21      1564\n",
      "         CRIME       0.34      0.27      0.31      1074\n",
      "     EDUCATION       0.30      0.14      0.19       300\n",
      " ENTERTAINMENT       0.43      0.00      0.00      5190\n",
      "   ENVIRONMENT       0.33      0.00      0.01       485\n",
      "  FOOD & DRINK       0.61      0.26      0.37      1886\n",
      "HEALTHY LIVING       0.00      0.00      0.00      1991\n",
      " HOME & LIVING       0.55      0.37      0.44      1323\n",
      "     PARENTING       0.63      0.41      0.50      3837\n",
      "      POLITICS       0.28      0.77      0.42     10606\n",
      "  QUEER VOICES       0.79      0.36      0.50      1885\n",
      "      RELIGION       0.55      0.24      0.33       728\n",
      "SCIENCE & TECH       0.61      0.05      0.10      1297\n",
      "        SPORTS       0.59      0.06      0.10      1543\n",
      "STYLE & BEAUTY       0.55      0.50      0.52      3670\n",
      "        TRAVEL       0.81      0.14      0.23      2980\n",
      "     U.S. NEWS       0.00      0.00      0.00       406\n",
      "      WELLNESS       0.21      0.45      0.28      5403\n",
      "    WORLD NEWS       0.00      0.00      0.00      2931\n",
      "\n",
      "      accuracy                           0.33     53438\n",
      "     macro avg       0.43      0.21      0.23     53438\n",
      "  weighted avg       0.41      0.33      0.28     53438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(ada, param_grid=ada_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_v, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_v, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_v,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_v,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_v)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a4def95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Best (Training) Params: {}\n",
      "Best (Training) Estimator: AdaBoostClassifier()\n",
      "Best (Training) Score: 0.34437707521293487\n",
      "Validation Score: 0.3426213555896553 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "ARTS & CULTURE       0.49      0.17      0.25      1187\n",
      "  BLACK VOICES       0.45      0.18      0.26      1350\n",
      "      BUSINESS       0.57      0.06      0.11      1802\n",
      "        COMEDY       0.15      0.10      0.12      1564\n",
      "         CRIME       0.35      0.23      0.27      1074\n",
      "     EDUCATION       0.31      0.16      0.21       300\n",
      " ENTERTAINMENT       0.00      0.00      0.00      5190\n",
      "   ENVIRONMENT       0.33      0.00      0.01       485\n",
      "  FOOD & DRINK       0.64      0.35      0.45      1886\n",
      "HEALTHY LIVING       0.00      0.00      0.00      1991\n",
      " HOME & LIVING       0.57      0.41      0.48      1323\n",
      "     PARENTING       0.60      0.43      0.50      3837\n",
      "      POLITICS       0.33      0.66      0.44     10606\n",
      "  QUEER VOICES       0.71      0.47      0.56      1885\n",
      "      RELIGION       0.52      0.28      0.36       728\n",
      "SCIENCE & TECH       0.00      0.00      0.00      1297\n",
      "        SPORTS       0.53      0.19      0.28      1543\n",
      "STYLE & BEAUTY       0.55      0.50      0.53      3670\n",
      "        TRAVEL       0.69      0.23      0.34      2980\n",
      "     U.S. NEWS       0.00      0.00      0.00       406\n",
      "      WELLNESS       0.20      0.66      0.30      5403\n",
      "    WORLD NEWS       0.30      0.00      0.00      2931\n",
      "\n",
      "      accuracy                           0.34     53438\n",
      "     macro avg       0.38      0.23      0.25     53438\n",
      "  weighted avg       0.36      0.34      0.30     53438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "adac = AdaBoostClassifier()\n",
    "grid = GridSearchCV(adac, param_grid=ada_params, cv=cv, n_jobs=-1, verbose=2).fit(X_train_vc, y_train)\n",
    "print('Best (Training) Params:', grid.best_params_)\n",
    "print('Best (Training) Estimator:', grid.best_estimator_)\n",
    "print('Best (Training) Score:', grid.best_estimator_.score(X_train_vc, y_train))\n",
    "print('Validation Score:',grid.best_estimator_.score(X_test_vc,y_test),'\\n')\n",
    "test_score = grid.best_estimator_.score(X_test_vc,y_test)\n",
    "print(classification_report(y_test,grid.best_estimator_.predict(X_test_vc)))\n",
    "# Save the best version on the validation data\n",
    "if test_score > best_test_score:\n",
    "    best_test_score = test_score\n",
    "    best_model = grid.best_estimator_\n",
    "    best_vect = vect_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11526b52",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Let's see who \"won\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11e07cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: MultinomialNB()\n",
      "Best Model Parameters: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': 'warn'}\n",
      "Best Test Score: 0.61\n",
      "Best Vectorizer: CountVectorizer(analyzer='char_wb', min_df=2, ngram_range=(2, 5))\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model:\",best_model)\n",
    "print(\"Best Model Parameters:\",best_model.get_params())\n",
    "print(\"Best Test Score:\",round(best_test_score,3))\n",
    "print(\"Best Vectorizer:\",best_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f245dd",
   "metadata": {},
   "source": [
    "The best accuracy score isn't that great, to be honest.  It uses the CountVectorizer and the Multinomial Naive Bayes classifer.  We can see if we can do a little bit better by iterating on a few parameters of either the vectorizer or the model.  Let's give that a go. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30adcc5",
   "metadata": {},
   "source": [
    "### Refinement - Classifier & Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7d69ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_params = {'alpha':[0.1, 1.0, 10]}\n",
    "min_dfs = [1,2,3,4]\n",
    "ngram_ranges = [(x,y) for x in [2,3,4] for y in [5,6]]\n",
    "iters = len(mnb_params.values()) * len(min_dfs) * len(ngram_ranges)\n",
    "count = 1\n",
    "best_mnb_score = 0\n",
    "best_mnb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36addd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting first vectorizer/model combo. . .\n",
      "1 of 24 complete\n",
      "2 of 24 complete\n",
      "3 of 24 complete\n",
      "4 of 24 complete\n",
      "5 of 24 complete\n",
      "6 of 24 complete\n",
      "7 of 24 complete\n",
      "8 of 24 complete\n",
      "9 of 24 complete\n",
      "10 of 24 complete\n",
      "11 of 24 complete\n",
      "12 of 24 complete\n",
      "13 of 24 complete\n",
      "14 of 24 complete\n",
      "15 of 24 complete\n",
      "16 of 24 complete\n",
      "17 of 24 complete\n",
      "18 of 24 complete\n",
      "19 of 24 complete\n",
      "20 of 24 complete\n",
      "21 of 24 complete\n",
      "22 of 24 complete\n",
      "23 of 24 complete\n",
      "24 of 24 complete\n"
     ]
    }
   ],
   "source": [
    "print('Starting first vectorizer/model combo. . .')\n",
    "for min_df in min_dfs:\n",
    "    for ngram_range in ngram_ranges:\n",
    "        vect_ct = CountVectorizer(min_df=min_df, ngram_range=ngram_range, analyzer='char_wb').fit(X_train1)\n",
    "        features = list(vect_ct.get_feature_names_out())\n",
    "        X_train1_vc = vect_ct.transform(X_train1)\n",
    "        X_train_vc = add_feature(X_train1_vc, X_train['headline_len'])\n",
    "        X_test1_vc = vect_ct.transform(X_test1)\n",
    "        X_test_vc = add_feature(X_test1_vc, X_test['headline_len'])\n",
    "        mnbc = MultinomialNB()\n",
    "        grid = GridSearchCV(mnbc, param_grid=mnb_params, cv=cv, n_jobs=-1, verbose=0).fit(X_train_vc, y_train)\n",
    "        test_score = grid.best_estimator_.score(X_test_vc,y_test)\n",
    "        # Save the best version on the validation data\n",
    "        if test_score > best_mnb_score:\n",
    "            best_mnb_score = test_score\n",
    "            best_mnb = grid.best_estimator_\n",
    "            best_vect_min_df, best_vect_ngram_range = (min_df, ngram_range)\n",
    "            best_vect = vect_ct\n",
    "        print(count,'of',iters,'complete')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b228e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters: {'alpha': 1.0, 'class_prior': None, 'fit_prior': True, 'force_alpha': 'warn'}\n",
      "Best Test Score: 0.622\n",
      "Best Count Vectorizer: CountVectorizer(analyzer='char_wb', min_df=2, ngram_range=(4, 6))\n",
      "Best Count Vectorizer min_df: 2\n",
      "Best Count Vectorizer ngram_range: (4, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Model Parameters:\",best_mnb.get_params())\n",
    "print(\"Best Test Score:\",round(best_mnb_score,3))\n",
    "print(\"Best Count Vectorizer:\",best_vect)\n",
    "print(\"Best Count Vectorizer min_df:\",best_vect_min_df)\n",
    "print(\"Best Count Vectorizer ngram_range:\",best_vect_ngram_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91883dc1",
   "metadata": {},
   "source": [
    "This additional iteration didn't do a whole lot better, unfortunately.  I suspect that there are other classifiers and larger parameter sets we could try.  For the one we created, let's take a look at classifying an example headline.  I've pulled it from [the Oregonian](https://www.oregonlive.com/silicon-forest/2024/02/amazon-will-start-buying-clean-power-for-oregon-data-centers.html) in February, 2024: \n",
    "\n",
    "**\"Amazon will start buying clean power for Oregon data centers\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0109ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = ['Amazon will start buying clean power for Oregon data centers']\n",
    "headline_matrix = best_vect.transform(headline)\n",
    "headline_matrix = add_feature(headline_matrix,len(headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b367a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BUSINESS'], dtype='<U14')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mnb.predict(headline_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d271f9",
   "metadata": {},
   "source": [
    "We can look at the probablities that the classifier assigned to the categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a961597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8004469844534391, 'BUSINESS'),\n",
       " (0.19955296623348417, 'HOME & LIVING'),\n",
       " (4.90455007158537e-08, 'SCIENCE & TECH'),\n",
       " (2.642809075639102e-10, 'CRIME'),\n",
       " (1.718235586647692e-12, 'TRAVEL'),\n",
       " (4.081351228446005e-13, 'FOOD & DRINK'),\n",
       " (3.534918987687584e-13, 'QUEER VOICES'),\n",
       " (3.2660277963371936e-13, 'SPORTS'),\n",
       " (1.7792301849396431e-13, 'POLITICS'),\n",
       " (1.617376383771402e-13, 'BLACK VOICES'),\n",
       " (1.416503103489661e-13, 'U.S. NEWS'),\n",
       " (4.146021706449459e-15, 'ARTS & CULTURE'),\n",
       " (2.5904616444714967e-15, 'HEALTHY LIVING'),\n",
       " (1.7679519983495307e-15, 'ENVIRONMENT'),\n",
       " (5.358270905661502e-16, 'COMEDY'),\n",
       " (1.523251423355252e-16, 'PARENTING'),\n",
       " (3.793212117096159e-17, 'STYLE & BEAUTY'),\n",
       " (5.975856729346842e-18, 'WORLD NEWS'),\n",
       " (2.282262281622486e-21, 'RELIGION'),\n",
       " (2.1229280193398124e-21, 'WELLNESS'),\n",
       " (8.48840044116647e-23, 'ENTERTAINMENT'),\n",
       " (1.4969827965042132e-24, 'EDUCATION')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = best_mnb.predict_proba(headline_matrix).tolist()[0]\n",
    "categories = best_mnb.classes_\n",
    "cat_probs = list(zip(probs,categories))\n",
    "cat_probs_sorted = sorted(cat_probs, key=lambda x:x[0], reverse=True)\n",
    "cat_probs_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e56d604",
   "metadata": {},
   "source": [
    "It is overwhelming for BUSINESS, and I'd say it got it right.  I think one of the other difficulties with this project is that many of the categories have signficant overlap.  Looking at the descriptions might help to continue to refine our predictions as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937783c6",
   "metadata": {},
   "source": [
    "Let's try one more.  This one is from the [NYT](https://www.nytimes.com/2024/02/09/world/europe/ukraine-oleksandr-syrsky-war-russia.html):\n",
    "\n",
    "**\"Ukraine Has a New Military Commander but the Problems Haven't Changed\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "52068a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = ['Ukraine Has a New Military Commander but the Problems Haven\\'t Changed']\n",
    "headline_matrix = best_vect.transform(headline)\n",
    "headline_matrix = add_feature(headline_matrix,len(headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d33d2c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WORLD NEWS'], dtype='<U14')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mnb.predict(headline_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "37c79572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9999999999998863, 'WORLD NEWS'),\n",
       " (6.314513004240485e-14, 'POLITICS'),\n",
       " (1.3508612418655215e-34, 'BUSINESS'),\n",
       " (3.724944661110938e-37, 'SCIENCE & TECH'),\n",
       " (2.8724250308358754e-37, 'WELLNESS'),\n",
       " (2.076527274719885e-37, 'QUEER VOICES'),\n",
       " (2.059427430381407e-39, 'COMEDY'),\n",
       " (6.943702428223902e-41, 'RELIGION'),\n",
       " (3.138214188894739e-41, 'HEALTHY LIVING'),\n",
       " (8.911636673159475e-43, 'PARENTING'),\n",
       " (3.7026321481975896e-44, 'BLACK VOICES'),\n",
       " (2.4183324491183298e-45, 'ARTS & CULTURE'),\n",
       " (6.165830573136674e-46, 'ENVIRONMENT'),\n",
       " (5.772458470157757e-48, 'ENTERTAINMENT'),\n",
       " (8.445010613882301e-49, 'U.S. NEWS'),\n",
       " (1.4385972766589937e-49, 'CRIME'),\n",
       " (1.561874305038305e-51, 'SPORTS'),\n",
       " (3.7476205431717555e-52, 'STYLE & BEAUTY'),\n",
       " (4.586233166200243e-53, 'EDUCATION'),\n",
       " (1.589651020776957e-54, 'TRAVEL'),\n",
       " (3.464690527668069e-58, 'HOME & LIVING'),\n",
       " (7.396299667826973e-60, 'FOOD & DRINK')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = best_mnb.predict_proba(headline_matrix).tolist()[0]\n",
    "categories = best_mnb.classes_\n",
    "cat_probs = list(zip(probs,categories))\n",
    "cat_probs_sorted = sorted(cat_probs, key=lambda x:x[0], reverse=True)\n",
    "cat_probs_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8641f",
   "metadata": {},
   "source": [
    "On the money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e773e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
